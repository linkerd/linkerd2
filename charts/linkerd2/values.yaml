# Default values for linkerd.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Values that are passed along to sub-charts
global:
  # The kubernetes cluster domain.
  clusterDomain: &cluster_domain cluster.local

  # The cluster networks for which service discovery is performed. This should
  # include the pod network but need not include the node network.
  #
  # By default, all private networks are specified so that resolution works in
  # typical Kubernetes environments.
  clusterNetworks: "10.0.0.0/8,100.64.0.0/10,172.16.0.0/12,192.168.0.0/16"

  imagePullPolicy: &image_pull_policy IfNotPresent
  controllerLogLevel: &controller_log_level info

  # control plane trace configuration
  controlPlaneTracing: false

  # control plane version. See Proxy section for proxy version
  linkerdVersion: &linkerd_version linkerdVersionValue

  namespace: linkerd

  # enables the use of EndpointSlice informers for the destination service;
  # enableEndpointSlices should be set to true only if EndpointSlice K8s feature gate is on;
  # the feature is still experimental.
  enableEndpointSlices: false

  # enabling this omits the NET_ADMIN capability in the PSP
  # and the proxy-init container when injecting the proxy;
  # requires the linkerd-cni plugin to already be installed
  cniEnabled: false

  identityTrustAnchorsPEM: |

  identityTrustDomain: *cluster_domain

  # url of existing prometheus
  prometheusUrl: ""
  # url of external grafana instance with reverse proxy configured
  grafanaUrl: ""

  # Additional annotations to add to all pods
  podAnnotations: {}

  # Additional labels to add to all pods
  podLabels: {}

  # proxy configuration
  proxy:
    enableExternalProfiles: false
    outboundConnectTimeout: 1000ms
    inboundConnectTimeout: 100ms
    image:
      name: ghcr.io/linkerd/proxy
      pullPolicy: *image_pull_policy
      version: *linkerd_version
    logLevel: warn,linkerd=info
    logFormat: plain
    ports:
      admin: 4191
      control: 4190
      inbound: 4143
      outbound: 4140
    # The `cpu.limit` and `cores` should be kept in sync. The value of `cores`
    # must be an integer and should typically be set by rounding up from the
    # limit. E.g. if cpu.limit is '1500m', cores should be 2.
    cores: 0
    resources:
      cpu:
        limit: ""
        request: ""
      memory:
        limit: ""
        request: ""
    trace:
      collectorSvcAddr: ""
      collectorSvcAccount: default
    uid: 2102
    # If set, the proxy's pre-stop hook will postpone the Kubernetes's SIGTERM signal
    # and wait for this duration before letting the proxy process the SIGTERM signal.
    # See https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks
    # for more info on container lifecycle hooks.
    waitBeforeExitSeconds: 0
    requireIdentityOnInboundPorts: ""

  # proxy-init configuration
  proxyInit:
    # Default set of ports to skip via itpables:
    # - SMTP (25,587) server-first
    # - HTTPS (443) opaque TLS
    # - MYSQL (3306) server-first
    # - Memcached (11211) clients do not issue any preamble, which breaks detection
    # - Postgres (5432) clients do not issue any preamble, which breaks detection
    ignoreInboundPorts: "25,443,587,3306,11211,5432"
    ignoreOutboundPorts: "25,443,587,3306,11211,5432"
    image:
      name: ghcr.io/linkerd/proxy-init
      pullPolicy: *image_pull_policy
      version: v1.3.6
    resources:
      cpu:
        limit: 100m
        request: 10m
      memory:
        limit: 50Mi
        request: 10Mi
    closeWaitTimeoutSecs: 0
    xtMountPath:
      mountPath: /run
      name: linkerd-proxy-init-xtables-lock

  # control plane annotations - do not edit
  createdByAnnotation: linkerd.io/created-by
  proxyInjectAnnotation: linkerd.io/inject
  proxyInjectDisabled: disabled

  # control plane labels - do not edit
  controllerComponentLabel: linkerd.io/control-plane-component
  controllerNamespaceLabel: linkerd.io/control-plane-ns
  linkerdNamespaceLabel: linkerd.io/is-control-plane
  workloadNamespaceLabel: linkerd.io/workload-ns

  # For Private docker registries, authentication is needed.
  #  Registry secrets are applied to the respective service accounts
  imagePullSecrets: []
  # - name: my-private-docker-registry-login-secret

# enforced host validation regular expression
enforcedHostRegexp: ""

enableH2Upgrade: true

omitWebhookSideEffects: false
webhookFailurePolicy: Ignore

# controller configuration
controllerImage: ghcr.io/linkerd/controller
controllerReplicas: 1
controllerUID: 2103


# destination configuration
# set resources for the sp-validator and its linkerd proxy respectively
# see global.proxy.resources for details.
#destinationResources:
#destinationProxyResources:


# web dashboard configuration
dashboard:
  replicas: 1

# debug configuration
debugContainer:
  image:
    name: ghcr.io/linkerd/debug
    pullPolicy: *image_pull_policy
    version: *linkerd_version

# identity configuration
identity:
  issuer:
    scheme: linkerd.io/tls

    clockSkewAllowance: 20s

    # must match the expiry date in crtPEM
    crtExpiry:

    # control plane annotation - do not edit
    crtExpiryAnnotation: linkerd.io/identity-issuer-expiry

    issuanceLifetime: 24h0m0s

    tls:
      # PEM-encoded certificate
      crtPEM: |

      # PEM-encoded ECDSA private key
      keyPEM: |

# set resources for identity and its linkerd proxy respectively
# see global.proxy.resources for details.
#identityResources:
#identityProxyResources:

# heartbeat configuration
disableHeartBeat: false
heartbeatSchedule: "0 0 * * *"

# proxy injector configuration
proxyInjector:
  externalSecret: false

  # Namespace selector used by admission webhook
  namespaceSelector:
    matchExpressions:
    - key: config.linkerd.io/admission-webhooks
      operator: NotIn
      values:
      - disabled

  # if empty, Helm will auto-generate these fields
  crtPEM: |

  keyPEM: |

  # if empty, Helm will auto-generate this field, unless externalSecret is set to true.
  caBundle: |

# set resources for proxy injector and its linkerd proxy respectively
# see global.proxy.resources for details.
#proxyInjectorResources:
#proxyInjectorProxyResources:

# service profile validator configuration
profileValidator:
  externalSecret: false

    # Namespace selector used by admission webhook
  namespaceSelector:
    matchExpressions:
    - key: config.linkerd.io/admission-webhooks
      operator: NotIn
      values:
      - disabled

  # if empty, Helm will auto-generate these fields
  crtPEM: |

  keyPEM: |

  # if empty, Helm will auto-generate this field, unless externalSecret is set to true.
  caBundle: |

# set resources for the sp-validator and its linkerd proxy respectively
# see global.proxy.resources for details.
#spValidatorResources:
#spValidatorProxyResources:

# set resources for controllers public API and its linkerd proxy respectively
# see global.proxy.resources for details.
#publicAPIResources:
#publicAPIProxyResources:

# tap configuration
tap:
  externalSecret: false
  # if empty, Helm will auto-generate these fields
  crtPEM: |

  keyPEM: |

  # if empty, Helm will auto-generate this field, unless externalSecret is set to true.
  caBundle: |

# set resources for tap and its linkerd proxy respectively
# see global.proxy.resources for details.
#tapResources:
#tapProxyResources:

# web configuration
webImage: ghcr.io/linkerd/web
# set resources for web UI and its linkerd proxy respectively
# see global.proxy.resources for details.
#webResources:
#webProxyResources:


# If the namespace is controlled by an external tool or can't be installed with Helm
# you can disable its installation. In this case:
# - The namespace created by the external tool must match the namespace value above
# - The external tool needs to create the namespace with the label:
#     config.linkerd.io/admission-webhooks: disabled
installNamespace: true

# Node selection constraints for control-plane components
# https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector.
nodeSelector:
  beta.kubernetes.io/os: linux

# Tolerations constraints for control-plane components
# https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
#tolerations:

# Configuration for Add-ons
# Full configuration fields https://github.com/linkerd/linkerd2/tree/master/charts/linkerd2#add-ons-configuration

grafana:
  enabled: true
  # image:
  #   name: ghcr.io/linkerd/grafana
  #   tag: latest
  # set resource requests and limits for grafana and its linkerd proxy respectively
  # see global.proxy.resources in the linkerd2 chart for details.
  # resources:
  # proxy:
  #   resources:

prometheus:
  enabled: true
  # image: prom/prometheus:v2.15.3
  # args:
  #  storage.tsdb.retention.time: 6h
  #  log.level: debug
  # globalConfig:
  #   scrape_interval: 10s
  #   scrape_timeout: 10s
  # scrapeConfigs:
  # - job_name: 'kubernetes-nodes'
  #   scheme: https
  #   tls_config:
  #     ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  #   bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  #   kubernetes_sd_configs:
  #   - role: node
  #   relabel_configs:
  #   - action: labelmap
  #     regex: __meta_kubernetes_node_label_(.+)
  # alertManagers:
  # - scheme: http
  #   static_configs:
  #   - targets:
  #     - "alertmanager.linkerd.svc:9093"
  # alertRelabelConfigs:
  # - action: labeldrop
  #   regex: prometheus_replica
  # ruleConfigMapMounts:
  # - name: alerting-rules
  #   subPath: alerting_rules.yml
  #   configMap: linkerd-prometheus-rules
  # - name: recording-rules
  #   subPath: recording_rules.yml
  #   configMap: linkerd-prometheus-rules
  ###
  ### Sidecar containers allow access to the prometheus data directory,
  ### e.g. for exporting data to non-prometheus systems.
  # sidecarContainers:
  # - name: sidecar
  #   image: gcr.io/myproject/stackdriver-prometheus-sidecar
  #   imagePullPolicy: Always
  #   command:
  #   - /bin/sh
  #   - -c
  #   - |
  #     exec /bin/stackdriver-prometheus-sidecar \
  #       --stackdriver.project-id=myproject \
  #       --stackdriver.kubernetes.location=us-central1 \
  #       --stackdriver.kubernetes.cluster-name=mycluster \
  #       --prometheus.wal-directory=/data/wal \
  #       --log.level=info
  #   volumeMounts:
  #   - mountPath: /data
  #     name: data
  #   ports:
  #   - name: foo
  #     containerPort: 9091
  #     protocol: TCP
  ### WARNING: persistence is experimental and has not been tested/vetted by the Linkerd team.
  ### As such, please refer to https://linkerd.io/2/tasks/exporting-metrics/ for the recommended approach to metrics data retention.
  # if enabled, creates a persistent volume claim for prometheus data
  # https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims
  # persistence:
  #   storageClass: ""
  #   accessMode: ReadWriteOnce
  #   size: 8Gi
  # resources:
  # proxy:
  #   resources:

tracing:
  enabled: false
  # collector:
  #  image: omnition/opencensus-collector:0.1.11
  #  resources:
  # jaeger:
  #  image: jaegertracing/all-in-one:1.19.2
  #  resources:
